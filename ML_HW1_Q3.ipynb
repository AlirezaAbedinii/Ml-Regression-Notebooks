{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extensive-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "elegant-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\Courses\\\\University Courses\\\\ML\\\\Homework\\\\HW1_ML\\\\p3_dataset\\\\data3_house_data.csv\")\n",
    "df = df.drop(['Id'], axis=1)\n",
    "train = df.iloc[0:1001 ,:]\n",
    "test = df.iloc[1001: ,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "metric-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradien_descent(X, X_TEST, degree, iteration_count, error_function):\n",
    "#     print(f'working on degree = {degree}, iteration count = {iteration_count}, error function = {error_function}')\n",
    "    errors = []\n",
    "    learning_rate = 0.0001#find_the_best_learning_rate(degree, iteration_count, error_function)\n",
    "#     print(f'the best learning rate = {learning_rate}')\n",
    "    m = len(x_train)\n",
    "    m_test = len(x_test)\n",
    "    theta_changes = []\n",
    "    theta = np.ones((degree+1, 1))*(1/(degree+1))\n",
    "    theta = theta.reshape(degree+1, 1)\n",
    "#     print(theta)\n",
    "#     X = np.ones((degree+1, len(x_train)))\n",
    "#     for i in range(degree+1):\n",
    "#         X[i] = x_train**i\n",
    "    X = X.T\n",
    "    \n",
    "    \n",
    "    np_y_train = y_train.to_numpy()\n",
    "    np_y_train = np.reshape(np_y_train, (len(np_y_train), 1))\n",
    "    \n",
    "    np_y_test = y_test.to_numpy()\n",
    "    np_y_test = np.reshape(np_y_test, (len(np_y_test), 1))\n",
    "    \n",
    "    h = np.dot(X, theta)\n",
    "    for i in range(iteration_count):\n",
    "        \n",
    "        if error_function == 'MSE':\n",
    "            d_theta = (2/m) * np.sum((h.T - np_y_train.T)*X.T, axis=1)\n",
    "            d_theta = d_theta.reshape(degree+1, 1)\n",
    "        elif error_function == 'RMSE':\n",
    "            d_theta = 2/m * np.sum((h.T - np_y_train.T)*X.T, axis=1) * 1/2 * (((1/(m)) * np.sum(((h.T - np_y_train.T)**2), axis=1))**(-1/2))\n",
    "            d_theta = d_theta.reshape(degree+1, 1)\n",
    "        elif error_function == 'MAE':\n",
    "            temp = np.greater(h.T, np_y_train.T)\n",
    "            coef = [1 if element else -1 for element in temp.T]\n",
    "            temp_X = X.T * coef\n",
    "            d_theta = 1/m * np.sum(temp_X, axis=1)\n",
    "            d_theta = d_theta.reshape(degree+1, 1)\n",
    "\n",
    "        theta = theta - learning_rate * d_theta\n",
    "        theta_changes.append(learning_rate * d_theta)\n",
    "        h = np.dot(X, theta)\n",
    "        \n",
    "        if error_function == 'MSE':\n",
    "            error = (1/m) * np.sum(((h.T - np_y_train.T)**2), axis=1)\n",
    "        elif error_function == 'RMSE':\n",
    "            error = ((1/m) * np.sum(((h.T - np_y_train.T)**2), axis=1))**(1/2)\n",
    "        elif error_function == 'MAE':\n",
    "            error = (1/m) * np.sum((abs(h.T - np_y_train.T)), axis=1)\n",
    "        errors.append([i, float(error)])\n",
    "        \n",
    "    print(f'final training error = {error}') \n",
    "    np_errors = np.array(errors)\n",
    "    test_result = np.dot(X_TEST, theta)\n",
    "    if error_function == 'MSE':\n",
    "        test_error = (1/m_test) * np.sum(((test_result.T - np_y_test.T)**2), axis=1)\n",
    "    elif error_function == 'RMSE':\n",
    "        test_error = ((1/m_test) * np.sum(((test_result.T - np_y_test.T)**2), axis=1))**(1/2)\n",
    "    elif error_function == 'MAE':\n",
    "        test_error = (1/m_test) * np.sum((abs(test_result.T - np_y_test.T)), axis=1)\n",
    "    \n",
    "    print(f'test error is {test_error}')\n",
    "#     plt.style.use(['dark_background'])\n",
    "#     plt.plot(np_errors[:,0], np_errors[:,1])\n",
    "#     plt.title(f'degree = {degree}, iteration count = {iteration_count}, cost function = {error_function}')\n",
    "#     plt.xlabel('iteration count')\n",
    "#     plt.ylabel('error')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "southeast-patrick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************\n",
      "number of training data is 10\n",
      "final training error = [57211.66812218]\n",
      "test error is [77923.8251409]\n",
      "*****************\n",
      "number of training data is 20\n",
      "final training error = [65595.80025223]\n",
      "test error is [86621.37624186]\n",
      "*****************\n",
      "number of training data is 30\n",
      "final training error = [69328.67726925]\n",
      "test error is [87741.92924291]\n",
      "*****************\n",
      "number of training data is 40\n",
      "final training error = [69624.02878734]\n",
      "test error is [83488.39555149]\n",
      "*****************\n",
      "number of training data is 50\n",
      "final training error = [73107.57672008]\n",
      "test error is [69338.29507502]\n",
      "*****************\n",
      "number of training data is 60\n",
      "final training error = [71225.86216051]\n",
      "test error is [69649.3969893]\n",
      "*****************\n",
      "number of training data is 70\n",
      "final training error = [67706.61364323]\n",
      "test error is [69708.31223058]\n",
      "*****************\n",
      "number of training data is 80\n",
      "final training error = [65833.94424034]\n",
      "test error is [70033.7520419]\n",
      "*****************\n",
      "number of training data is 90\n",
      "final training error = [64679.95131009]\n",
      "test error is [70230.56078582]\n",
      "*****************\n",
      "number of training data is 100\n",
      "final training error = [67789.35510494]\n",
      "test error is [70336.37084138]\n",
      "*****************\n",
      "number of training data is 110\n",
      "final training error = [65612.83513274]\n",
      "test error is [70627.90851105]\n",
      "*****************\n",
      "number of training data is 120\n",
      "final training error = [63757.49651855]\n",
      "test error is [70797.41941838]\n",
      "*****************\n",
      "number of training data is 130\n",
      "final training error = [64643.92455672]\n",
      "test error is [71490.25618537]\n",
      "*****************\n",
      "number of training data is 140\n",
      "final training error = [67405.72377215]\n",
      "test error is [70816.32726767]\n",
      "*****************\n",
      "number of training data is 150\n",
      "final training error = [69673.49993444]\n",
      "test error is [71767.87591124]\n",
      "*****************\n",
      "number of training data is 160\n",
      "final training error = [71028.01990932]\n",
      "test error is [72532.89968887]\n",
      "*****************\n",
      "number of training data is 170\n",
      "final training error = [70698.85516284]\n",
      "test error is [71996.69109278]\n",
      "*****************\n",
      "number of training data is 180\n",
      "final training error = [69688.02579306]\n",
      "test error is [71851.57756375]\n",
      "*****************\n",
      "number of training data is 190\n",
      "final training error = [71181.52683583]\n",
      "test error is [72456.10375394]\n",
      "*****************\n",
      "number of training data is 200\n",
      "final training error = [70745.44258126]\n",
      "test error is [72702.75962256]\n",
      "*****************\n",
      "number of training data is 210\n",
      "final training error = [69920.22333662]\n",
      "test error is [72665.4621081]\n",
      "*****************\n",
      "number of training data is 220\n",
      "final training error = [69586.47998412]\n",
      "test error is [72389.70922967]\n",
      "*****************\n",
      "number of training data is 230\n",
      "final training error = [69634.24881789]\n",
      "test error is [70711.46666649]\n",
      "*****************\n",
      "number of training data is 240\n",
      "final training error = [70048.98803327]\n",
      "test error is [70691.67774968]\n",
      "*****************\n",
      "number of training data is 250\n",
      "final training error = [69156.77309032]\n",
      "test error is [70558.82163745]\n",
      "*****************\n",
      "number of training data is 260\n",
      "final training error = [69318.19721538]\n",
      "test error is [70882.53914311]\n",
      "*****************\n",
      "number of training data is 270\n",
      "final training error = [75622.87504793]\n",
      "test error is [68780.9164269]\n",
      "*****************\n",
      "number of training data is 280\n",
      "final training error = [76295.57044545]\n",
      "test error is [68857.69474215]\n",
      "*****************\n",
      "number of training data is 290\n",
      "final training error = [76814.71504249]\n",
      "test error is [68823.19397759]\n",
      "*****************\n",
      "number of training data is 300\n",
      "final training error = [76588.59849453]\n",
      "test error is [68745.69378796]\n",
      "*****************\n",
      "number of training data is 310\n",
      "final training error = [77088.34106922]\n",
      "test error is [68765.96247313]\n",
      "*****************\n",
      "number of training data is 320\n",
      "final training error = [77550.29975659]\n",
      "test error is [68731.35263388]\n",
      "*****************\n",
      "number of training data is 330\n",
      "final training error = [77070.49621067]\n",
      "test error is [68607.06098005]\n",
      "*****************\n",
      "number of training data is 340\n",
      "final training error = [77360.52713107]\n",
      "test error is [68591.12096239]\n",
      "*****************\n",
      "number of training data is 350\n",
      "final training error = [76923.83341877]\n",
      "test error is [68554.9808171]\n",
      "*****************\n",
      "number of training data is 360\n",
      "final training error = [76479.59984259]\n",
      "test error is [68378.09772205]\n",
      "*****************\n",
      "number of training data is 370\n",
      "final training error = [78128.56325022]\n",
      "test error is [68339.33571968]\n",
      "*****************\n",
      "number of training data is 380\n",
      "final training error = [77507.96769425]\n",
      "test error is [68308.37050906]\n",
      "*****************\n",
      "number of training data is 390\n",
      "final training error = [77887.75564487]\n",
      "test error is [68293.52746003]\n",
      "*****************\n",
      "number of training data is 400\n",
      "final training error = [78730.39557794]\n",
      "test error is [68410.81005635]\n",
      "*****************\n",
      "number of training data is 410\n",
      "final training error = [78389.96630934]\n",
      "test error is [68251.60163799]\n",
      "*****************\n",
      "number of training data is 420\n",
      "final training error = [77837.23411515]\n",
      "test error is [68205.96751257]\n",
      "*****************\n",
      "number of training data is 430\n",
      "final training error = [77978.74156208]\n",
      "test error is [68211.4082796]\n",
      "*****************\n",
      "number of training data is 440\n",
      "final training error = [78623.37194957]\n",
      "test error is [68232.85338676]\n",
      "*****************\n",
      "number of training data is 450\n",
      "final training error = [78396.72907829]\n",
      "test error is [68156.52233312]\n",
      "*****************\n",
      "number of training data is 460\n",
      "final training error = [78058.21039164]\n",
      "test error is [68145.48393364]\n",
      "*****************\n",
      "number of training data is 470\n",
      "final training error = [77806.14539895]\n",
      "test error is [68109.94323782]\n",
      "*****************\n",
      "number of training data is 480\n",
      "final training error = [77403.77509558]\n",
      "test error is [68075.07395574]\n",
      "*****************\n",
      "number of training data is 490\n",
      "final training error = [77739.81294384]\n",
      "test error is [68062.32077639]\n",
      "*****************\n",
      "number of training data is 500\n",
      "final training error = [78292.09856038]\n",
      "test error is [68099.31221983]\n",
      "*****************\n",
      "number of training data is 510\n",
      "final training error = [78057.29130133]\n",
      "test error is [68108.60814287]\n",
      "*****************\n",
      "number of training data is 520\n",
      "final training error = [78068.88885599]\n",
      "test error is [68064.26317593]\n",
      "*****************\n",
      "number of training data is 530\n",
      "final training error = [77748.12983603]\n",
      "test error is [67998.32272494]\n",
      "*****************\n",
      "number of training data is 540\n",
      "final training error = [78198.85704125]\n",
      "test error is [68013.39966902]\n",
      "*****************\n",
      "number of training data is 550\n",
      "final training error = [78181.36720447]\n",
      "test error is [67968.40337107]\n",
      "*****************\n",
      "number of training data is 560\n",
      "final training error = [78418.39098574]\n",
      "test error is [67902.1478769]\n",
      "*****************\n",
      "number of training data is 570\n",
      "final training error = [78452.63778595]\n",
      "test error is [67900.98445563]\n",
      "*****************\n",
      "number of training data is 580\n",
      "final training error = [81755.32065457]\n",
      "test error is [67892.69298933]\n",
      "*****************\n",
      "number of training data is 590\n",
      "final training error = [81774.52760719]\n",
      "test error is [67910.27154063]\n",
      "*****************\n",
      "number of training data is 600\n",
      "final training error = [81642.7142534]\n",
      "test error is [67858.56325333]\n",
      "*****************\n",
      "number of training data is 610\n",
      "final training error = [81373.40739885]\n",
      "test error is [67844.33748841]\n",
      "*****************\n",
      "number of training data is 620\n",
      "final training error = [80858.35770369]\n",
      "test error is [67821.62105937]\n",
      "*****************\n",
      "number of training data is 630\n",
      "final training error = [80569.48312096]\n",
      "test error is [67839.32778828]\n",
      "*****************\n",
      "number of training data is 640\n",
      "final training error = [80493.08252598]\n",
      "test error is [67880.19549619]\n",
      "*****************\n",
      "number of training data is 650\n",
      "final training error = [81007.77371206]\n",
      "test error is [67794.55202023]\n",
      "*****************\n",
      "number of training data is 660\n",
      "final training error = [80575.90961662]\n",
      "test error is [67792.17743212]\n",
      "*****************\n",
      "number of training data is 670\n",
      "final training error = [82237.549961]\n",
      "test error is [67822.50223009]\n",
      "*****************\n",
      "number of training data is 680\n",
      "final training error = [81908.53059391]\n",
      "test error is [67770.06919994]\n",
      "*****************\n",
      "number of training data is 690\n",
      "final training error = [81772.5402796]\n",
      "test error is [67767.86141806]\n",
      "*****************\n",
      "number of training data is 700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final training error = [81340.23530891]\n",
      "test error is [67724.79282213]\n",
      "*****************\n",
      "number of training data is 710\n",
      "final training error = [80869.38999205]\n",
      "test error is [67709.79968587]\n",
      "*****************\n",
      "number of training data is 720\n",
      "final training error = [80475.54073382]\n",
      "test error is [67696.76798338]\n",
      "*****************\n",
      "number of training data is 730\n",
      "final training error = [80595.09226464]\n",
      "test error is [67693.88761135]\n",
      "*****************\n",
      "number of training data is 740\n",
      "final training error = [80456.64808529]\n",
      "test error is [67678.99506867]\n",
      "*****************\n",
      "number of training data is 750\n",
      "final training error = [81480.09540702]\n",
      "test error is [67669.34479168]\n",
      "*****************\n",
      "number of training data is 760\n",
      "final training error = [81176.29350368]\n",
      "test error is [67644.61420061]\n",
      "*****************\n",
      "number of training data is 770\n",
      "final training error = [80926.58574546]\n",
      "test error is [67641.54932491]\n",
      "*****************\n",
      "number of training data is 780\n",
      "final training error = [80723.08684568]\n",
      "test error is [67641.72903355]\n",
      "*****************\n",
      "number of training data is 790\n",
      "final training error = [80418.56206197]\n",
      "test error is [67612.95698596]\n",
      "*****************\n",
      "number of training data is 800\n",
      "final training error = [79996.30834944]\n",
      "test error is [67599.93619252]\n",
      "*****************\n",
      "number of training data is 810\n",
      "final training error = [79783.04361697]\n",
      "test error is [67559.60191783]\n",
      "*****************\n",
      "number of training data is 820\n",
      "final training error = [80132.31376975]\n",
      "test error is [67575.50758762]\n",
      "*****************\n",
      "number of training data is 830\n",
      "final training error = [80041.69573972]\n",
      "test error is [67557.23874102]\n",
      "*****************\n",
      "number of training data is 840\n",
      "final training error = [79852.9348089]\n",
      "test error is [67520.07665433]\n",
      "*****************\n",
      "number of training data is 850\n",
      "final training error = [79611.18491153]\n",
      "test error is [67531.89743904]\n",
      "*****************\n",
      "number of training data is 860\n",
      "final training error = [79454.77739033]\n",
      "test error is [67511.87855612]\n",
      "*****************\n",
      "number of training data is 870\n",
      "final training error = [80177.53374226]\n",
      "test error is [67516.05762479]\n",
      "*****************\n",
      "number of training data is 880\n",
      "final training error = [80222.06133853]\n",
      "test error is [67519.27707756]\n",
      "*****************\n",
      "number of training data is 890\n",
      "final training error = [79869.69140985]\n",
      "test error is [67500.58271731]\n",
      "*****************\n",
      "number of training data is 900\n",
      "final training error = [79571.89218519]\n",
      "test error is [67486.66741927]\n",
      "*****************\n",
      "number of training data is 910\n",
      "final training error = [79312.81796195]\n",
      "test error is [67456.59188001]\n",
      "*****************\n",
      "number of training data is 920\n",
      "final training error = [79144.81613257]\n",
      "test error is [67452.44617858]\n",
      "*****************\n",
      "number of training data is 930\n",
      "final training error = [78980.89303574]\n",
      "test error is [67436.42524542]\n",
      "*****************\n",
      "number of training data is 940\n",
      "final training error = [78766.7577075]\n",
      "test error is [67419.60602945]\n",
      "*****************\n",
      "number of training data is 950\n",
      "final training error = [78919.77864776]\n",
      "test error is [67408.02891982]\n",
      "*****************\n",
      "number of training data is 960\n",
      "final training error = [78643.19855411]\n",
      "test error is [67413.41961494]\n",
      "*****************\n",
      "number of training data is 970\n",
      "final training error = [79221.13391613]\n",
      "test error is [67395.05495257]\n",
      "*****************\n",
      "number of training data is 980\n",
      "final training error = [81266.62434458]\n",
      "test error is [67401.60571296]\n",
      "*****************\n",
      "number of training data is 990\n",
      "final training error = [80899.29334628]\n",
      "test error is [67397.11968291]\n",
      "*****************\n",
      "number of training data is 1000\n",
      "final training error = [80661.92787782]\n",
      "test error is [67397.3911811]\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = test.iloc[:, :6], test.iloc[:, 6]\n",
    "for i in range(100):\n",
    "    x_train, y_train = train.iloc[:10+(i*10), :6], train.iloc[:10+(i*10), 6]\n",
    "    np_X = x_train.to_numpy()\n",
    "    np_X_TEST = x_test.to_numpy()\n",
    "    print('*****************')\n",
    "    print(f'number of training data is {(i+1)*10}')\n",
    "    gradien_descent(X=np_X.T, X_TEST=np_X_TEST, degree=5, iteration_count=1000, error_function='RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-newman",
   "metadata": {
    "direction": "rtl"
   },
   "source": [
    "### هرچه تعداد داده های آموزشی بیشتر می‌شود:\n",
    "### خطای آموزش بیشتر می‌شود\n",
    "### خطای تست کمتر می‌شود\n",
    "### اختلاف خطای آموزش و تست (معادل واریانس) کمتر می‌شود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "helpful-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradien_descent_with_regularization(X, X_TEST, degree, iteration_count, error_function, reg_lambda=0):\n",
    "#     print(f'working on degree = {degree}, iteration count = {iteration_count}, error function = {error_function}')\n",
    "    errors = []\n",
    "    learning_rate = 0.0001#find_the_best_learning_rate(degree, iteration_count, error_function)\n",
    "#     print(f'the best learning rate = {learning_rate}')\n",
    "    m = len(x_train)\n",
    "    m_test = len(x_test)\n",
    "    theta_changes = []\n",
    "    theta = np.ones((degree+1, 1))*(1/(degree+1))\n",
    "    theta = theta.reshape(degree+1, 1)\n",
    "#     print(theta)\n",
    "#     X = np.ones((degree+1, len(x_train)))\n",
    "#     for i in range(degree+1):\n",
    "#         X[i] = x_train**i\n",
    "    X = X.T\n",
    "    \n",
    "    \n",
    "    np_y_train = y_train.to_numpy()\n",
    "    np_y_train = np.reshape(np_y_train, (len(np_y_train), 1))\n",
    "    \n",
    "    np_y_test = y_test.to_numpy()\n",
    "    np_y_test = np.reshape(np_y_test, (len(np_y_test), 1))\n",
    "    \n",
    "    h = np.dot(X, theta)\n",
    "    for i in range(iteration_count):\n",
    "        \n",
    "        if error_function == 'MSE':\n",
    "            d_theta = (2/m) * np.sum((h.T - np_y_train.T)*X.T, axis=1) + (2/m)*reg_lambda*np.sum(theta)\n",
    "            d_theta = d_theta.reshape(degree+1, 1)\n",
    "        elif error_function == 'RMSE':\n",
    "            d_theta = 2/m * np.sum((h.T - np_y_train.T)*X.T, axis=1) * 1/2 * (((1/(m)) * np.sum(((h.T - np_y_train.T)**2), axis=1))**(-1/2)) + (2/m)*2*reg_lambda*np.sum(theta**2)\n",
    "            d_theta = d_theta.reshape(degree+1, 1)\n",
    "        elif error_function == 'MAE':\n",
    "            temp = np.greater(h.T, np_y_train.T)\n",
    "            coef = [1 if element else -1 for element in temp.T]\n",
    "            temp_X = X.T * coef\n",
    "            d_theta = 1/m * np.sum(temp_X, axis=1)\n",
    "            d_theta = d_theta.reshape(degree+1, 1)\n",
    "\n",
    "        theta = theta - learning_rate * d_theta\n",
    "        theta_changes.append(np.linalg.norm(theta))\n",
    "        h = np.dot(X, theta)\n",
    "        \n",
    "        if error_function == 'MSE':\n",
    "            error = (1/m) * np.sum(((h.T - np_y_train.T)**2), axis=1) + (1/m)*reg_lambda*np.sum(theta**2)\n",
    "        elif error_function == 'RMSE':\n",
    "            error = ((1/m) * np.sum(((h.T - np_y_train.T)**2), axis=1))**(1/2) + (1/m)*reg_lambda*np.sum(theta**2)\n",
    "        elif error_function == 'MAE':\n",
    "            error = (1/m) * np.sum((abs(h.T - np_y_train.T)), axis=1)\n",
    "        errors.append([i, float(error)])\n",
    "        \n",
    "    print(f'final training error = {error}') \n",
    "    np_errors = np.array(errors)\n",
    "    test_result = np.dot(X_TEST, theta)\n",
    "    if error_function == 'MSE':\n",
    "        test_error = (1/m_test) * np.sum(((test_result.T - np_y_test.T)**2), axis=1) + (1/m)*reg_lambda*np.sum(theta**2)\n",
    "    elif error_function == 'RMSE':\n",
    "        test_error = ((1/m_test) * np.sum(((test_result.T - np_y_test.T)**2), axis=1)+ (1/m)*reg_lambda*np.sum(theta**2))**(1/2) \n",
    "    elif error_function == 'MAE':\n",
    "        test_error = (1/m_test) * np.sum((abs(test_result.T - np_y_test.T)), axis=1)\n",
    "    \n",
    "    print(f'test error is {test_error}')\n",
    "    np_theta_changes = np.array(theta_changes)\n",
    "    #np_theta_changes=np_theta_changes.transpose(2,0,1).reshape(degree+1,-1)\n",
    "    \n",
    "    plt.plot(range(iteration_count), np_theta_changes)\n",
    "#     plt.legend(range(degree+1))\n",
    "    plt.title('theta changes')\n",
    "    plt.xlabel('iteration count')\n",
    "    plt.ylabel('magnitude of theta')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "confused-extent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final training error = [73149.77306194]\n",
      "test error is [69390.21634091]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train = train.iloc[:10+(4*10), :6], train.iloc[:10+(4*10), 6]\n",
    "np_X = x_train.to_numpy()\n",
    "np_X_TEST = x_test.to_numpy()\n",
    "gradien_descent_with_regularization(X=np_X.T, X_TEST=np_X_TEST, degree=5, iteration_count=1000, error_function='RMSE', reg_lambda=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
